{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5046e9f7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1 - Test the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Disable useless warnings for this project\n",
    "warnings.simplefilter('ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=UserWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# To construct vectorized environments for Atari games\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "# To do frame stacking with vectorized environments\n",
    "from stable_baselines3.common.vec_env import VecFrameStack"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "a073d349",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.1 - Play games with random actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb5cb92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the game environment with OpenAI Gym from the ALE rom\n",
    "env = gym.make('ALE/SpaceInvaders-v5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a0f0ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Display the meanings of all possible actions\n",
    "env.unwrapped.get_action_meanings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aac02b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for episode in range(5):\n",
    "    # Reset the environment\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        # Choose a random action among available actions\n",
    "        action = env.action_space.sample()\n",
    "        # Perform an action in the environment\n",
    "        # It returns :\n",
    "        #   the observation of the current environment\n",
    "        #   the amount of reward returned after previous action\n",
    "        #   the done boolean which is true whether the episode has ended\n",
    "        #   the info dictionary contains auxiliary diagnostic information\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        # Update the overall score with reward of the performed action\n",
    "        score += reward\n",
    "\n",
    "    print(f'Episode : {episode + 1} --> Score : {score}')\n",
    "\n",
    "# Close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a394f2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.2 - Stack frames to represent movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e3329",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the game environment\n",
    "# Preprocess to the environment for Atari games\n",
    "# Vectorize the environment\n",
    "env = make_atari_env('ALE/SpaceInvaders-v5')\n",
    "# Stack the last 4 frames of the game to have a dimension of movement\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73fc330",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "# Perform 10 actions and show them to visualize how the frame stacking works\n",
    "for i in range(10):\n",
    "    plt.figure(figsize=(20, 16))\n",
    "\n",
    "    # Print 4 images which represents the frames stacked in the environment\n",
    "    for idx in range(obs.shape[3]):\n",
    "        plt.subplot(1, 4, idx + 1)\n",
    "        plt.imshow(obs[0][:, :, idx])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step([action])\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a817f409",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2 - Train and evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Stable Baselines3 Contrib : Contrib package for Stable Baselines3 (SB3) - Experimental code\n",
    "# Reinforcement learning algorithms\n",
    "from sb3_contrib import MaskablePPO, QRDQN\n",
    "# To mask actions in an environment\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "# To do preprocessing for Atari games\n",
    "from stable_baselines3.common.atari_wrappers import AtariWrapper\n",
    "# To save and evaluate regularly a model during training\n",
    "from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback, EvalCallback\n",
    "# To construct vectorized environments\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "# To evaluate a model\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "# To give linear function to hyperparams (e.g. learning rate, clip range, ...)\n",
    "from stable_baselines3.common.type_aliases import Schedule"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to mask some actions from the available actions in the environment\n",
    "def mask_fn(_env: gym.Env) -> np.ndarray:\n",
    "    return [True, True, True, True, False, False]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Custom wrapper to apply multiple wrappers to the environment\n",
    "class ActionMaskerAtariWrapper(gym.Wrapper):\n",
    "\n",
    "    def __init__(self, _env: gym.Env):\n",
    "        # Wrap the environment to expose a function which return masked actions\n",
    "        _env = ActionMasker(_env, mask_fn)\n",
    "        # Wrap the environment to preprocess it for Atari games\n",
    "        _env = AtariWrapper(_env)\n",
    "\n",
    "        super().__init__(_env)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to make a linear evolution with the initial value as coefficient\n",
    "def linear_schedule(initial_value: float) -> Schedule:\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        return progress_remaining * initial_value\n",
    "\n",
    "    return func"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "4bfd5e45",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.1 - Setup train and evaluation environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968eca2e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create 8 vectorized environments\n",
    "# Wrap the environments to do some preprocessing\n",
    "env = make_vec_env('ALE/SpaceInvaders-v5',\n",
    "                   n_envs=8,\n",
    "                   wrapper_class=ActionMaskerAtariWrapper)\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be552e0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_env = make_vec_env('ALE/SpaceInvaders-v5',\n",
    "                        wrapper_class=ActionMaskerAtariWrapper)\n",
    "eval_env = VecFrameStack(eval_env, n_stack=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdadfeb4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.2 - Setup checkpoint and evaluation callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb9dbf4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a checkpoint callback to save the model every million steps\n",
    "# The save frequency refers to each environment (125 000 * 8 = 1 000 000)\n",
    "checkpoint_callback = CheckpointCallback(save_freq=125_000,\n",
    "                                         save_path='logs/',\n",
    "                                         name_prefix='space_invaders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2401778f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create an evaluation callback to mesure the evolution of the model every hundred thousand steps\n",
    "# The evaluation frequency refers to each environment (12 500 * 8 = 100 000)\n",
    "eval_callback = EvalCallback(eval_env,\n",
    "                             best_model_save_path='logs/',\n",
    "                             eval_freq=12_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447960ee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of callbacks to give it at the initialisation of the model learning\n",
    "callback_list = CallbackList([checkpoint_callback, eval_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9cc4ed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.3 - Train a model with [QR-DQN algorithm](https://sb3-contrib.readthedocs.io/en/master/modules/qrdqn.html])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb12111e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the paths where logs will be stored for this model\n",
    "checkpoint_callback.name_prefix = 'qrdqn/space_invaders'\n",
    "eval_callback.best_model_save_path = 'logs/qrdqn/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dad425",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the model with atari hyperparams from https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/qrdqn.yml\n",
    "# Hyperparams are the following :\n",
    "#   - CnnPolicy : the policy class for QR-DQN when using images as input\n",
    "#   - env : 8 vectorized environments with 4 frames stacked each\n",
    "#   - optimize_memory_usage=True : enable a memory efficient variant of the replay buffer at a cost of more complexity\n",
    "#   - exploration_fraction=0.025 : fraction of entire training period over which the exploration rate is reduced\n",
    "#   - verbose=1 : the verbosity level: 0 no output, 1 info, 2 debug\n",
    "#   - tensorboard_log='logs/tensorboard/' : the log location for tensorboard\n",
    "model = QRDQN('CnnPolicy',\n",
    "              env,\n",
    "              optimize_memory_usage=True,\n",
    "              exploration_fraction=0.025,\n",
    "              verbose=1,\n",
    "              tensorboard_log='logs/tensorboard/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b27cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model, execute callbacks and log to follow the evolution with tensorboard\n",
    "model.learn(total_timesteps=int(1e7),\n",
    "            callback=callback_list,\n",
    "            log_interval=2000,\n",
    "            tb_log_name='qrdqn_space_invaders')\n",
    "# Save the model in a zip file\n",
    "model.save('qrdqn_space_invaders')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a3a6f9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.4 - Train a model with [Maskable PPO algorithm](https://sb3-contrib.readthedocs.io/en/master/modules/ppo_mask.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c24c4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_callback.name_prefix = 'maskable_ppo/space_invaders'\n",
    "eval_callback.best_model_save_path = 'logs/maskable_ppo/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a4f16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the model with atari hyperparams from https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/ppo.yml\n",
    "# Hyperparams are the following :\n",
    "#   - CnnPolicy : Convolutional Neural Network policy class for actor-critic algorithms\n",
    "#   - env : 8 vectorized environments with 4 frames stacked each\n",
    "#   - learning_rate=linear_schedule(2.5e-4) : learning rate function of the current progress remaining (from 1 to 0)\n",
    "#   - n_steps=128 : number of steps to run for each environment per update\n",
    "#   - batch_size=256 : Minibatch size (where batch size is n_steps times the number of environment copies running in parallel)\n",
    "#   - n_epochs=4 : number of epoch when optimizing the surrogate loss\n",
    "#   - clip_range=linear_schedule(0.1) : clipping function of the current progress remaining (from 1 to 0)\n",
    "#   - ent_coef=0.01 : entropy coefficient for the loss calculation\n",
    "#   - vf_coef=0.5 : value function coefficient for the loss calculation\n",
    "#   - verbose=1 : the verbosity level: 0 no output, 1 info, 2 debug\n",
    "#   - tensorboard_log='logs/tensorboard/' : the log location for tensorboard\n",
    "model = MaskablePPO('CnnPolicy',\n",
    "                    env,\n",
    "                    learning_rate=linear_schedule(2.5e-4),\n",
    "                    n_steps=128,\n",
    "                    batch_size=256,\n",
    "                    n_epochs=4,\n",
    "                    clip_range=linear_schedule(0.1),\n",
    "                    ent_coef=0.01,\n",
    "                    vf_coef=0.5,\n",
    "                    verbose=1,\n",
    "                    tensorboard_log='logs/tensorboard/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419af6d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=int(1e7),\n",
    "            callback=callback_list,\n",
    "            log_interval=100,\n",
    "            tb_log_name='maskable_ppo_space_invaders')\n",
    "model.save('maskable_ppo_space_invaders')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84365397",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.5 - Error : Python process interruption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c70049",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The python kernel crashed a little bit after 6M steps, so the model is reset with saved parameters of the zip file of 6M steps to train 4M more steps to reach 10M steps in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bd3915",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_callback.name_prefix = 'maskable_ppo/follow-up/space_invaders'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5efecf7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reinitialize the model with the hyperparams updated with values from before the interruption\n",
    "model = MaskablePPO('CnnPolicy',\n",
    "                    env,\n",
    "                    learning_rate=linear_schedule(1.0001e-4),\n",
    "                    n_steps=128,\n",
    "                    batch_size=256,\n",
    "                    n_epochs=4,\n",
    "                    clip_range=linear_schedule(0.04),\n",
    "                    ent_coef=0.01,\n",
    "                    vf_coef=0.5,\n",
    "                    verbose=1,\n",
    "                    tensorboard_log='logs/tensorboard/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c07932c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set the model parameters to values from the last saved model\n",
    "model.set_parameters('logs/maskable_ppo/space_invaders_6000000_steps.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5816bbd3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=int(4e6),\n",
    "            callback=callback_list,\n",
    "            log_interval=100,\n",
    "            tb_log_name='maskable_ppo_space_invaders')\n",
    "model.save('maskable_ppo_space_invaders')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a1fc64",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3 - See the results of trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28cd41b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Function to evaluate a model on an environment and render the played game\n",
    "def demo(_model, _env):\n",
    "    mean_reward, std_reward = evaluate_policy(_model, _env, render=True)\n",
    "    print(f'mean_reward = {mean_reward:.2f} +/- {std_reward:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cadda7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.1 - Setup the demonstration environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca65776",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "demo_env = make_vec_env('ALE/SpaceInvaders-v5',\n",
    "                        wrapper_class=ActionMaskerAtariWrapper)\n",
    "demo_env = VecFrameStack(demo_env, n_stack=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ff62e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.2 - Demo of models trained with [QR-DQN algorithm](https://sb3-contrib.readthedocs.io/en/master/modules/qrdqn.html])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde839f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the model with a saved zip file\n",
    "demo_model = QRDQN.load('logs/qrdqn/best_model')\n",
    "demo(demo_model, demo_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a57ad5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "demo_model = QRDQN.load('qrdqn_space_invaders')\n",
    "demo(demo_model, demo_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cff938",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.3 - Demo of models trained with [Maskable PPO algorithm](https://sb3-contrib.readthedocs.io/en/master/modules/ppo_mask.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c473658",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "demo_model = MaskablePPO.load('logs/maskable_ppo/best_model')\n",
    "demo(demo_model, demo_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85907e1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "demo_model = MaskablePPO.load('maskable_ppo_space_invaders')\n",
    "demo(demo_model, demo_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6582d65a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Bonus - Make a gif of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import imageio"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gif_env = make_atari_env('ALE/SpaceInvaders-v5')\n",
    "gif_env = VecFrameStack(gif_env, n_stack=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gif_model = MaskablePPO.load('maskable_ppo_space_invaders')\n",
    "gif_model.set_env(gif_env)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://stable-baselines3.readthedocs.io/en/master/guide/examples.html#bonus-make-a-gif-of-a-trained-agent\n",
    "images = []\n",
    "obs = gif_env.reset()\n",
    "img = gif_env.render(mode='rgb_array')\n",
    "\n",
    "for i in range(350):\n",
    "    images.append(img)\n",
    "    action, _ = gif_model.predict(obs)\n",
    "    obs, _, _, _ = gif_env.step(action)\n",
    "    img = gif_env.render(mode='rgb_array')\n",
    "\n",
    "gif_env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imageio.mimsave('../images/space_invaders.gif',\n",
    "                [np.array(img) for i, img in enumerate(images) if i % 2 == 0],\n",
    "                fps=29)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
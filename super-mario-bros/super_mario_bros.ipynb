{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d353d59",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1 - Test the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Disable useless warnings for this project\n",
    "warnings.simplefilter('ignore', category=UserWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_super_mario_bros\n",
    "\n",
    "# To switch from RGB to gray scale\n",
    "# To resize the observation of the environment\n",
    "from gym.wrappers import GrayScaleObservation, ResizeObservation\n",
    "# To move Mario only to the right\n",
    "# To move Mario to the right or only jump or go to the left\n",
    "from gym_super_mario_bros.actions import RIGHT_ONLY, SIMPLE_MOVEMENT\n",
    "# The Super Mario Bros environment\n",
    "from gym_super_mario_bros.smb_env import SuperMarioBrosEnv\n",
    "from matplotlib import pyplot as plt\n",
    "# To wrap the game environment to simulate actions from a game controller\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "# To clip AI agent rewards to -1, 0 or 1 depending on the sign of the reward\n",
    "# To skip frames during training\n",
    "# To set a maximum to the AI agent to not perform any action\n",
    "from stable_baselines3.common.atari_wrappers import ClipRewardEnv, MaxAndSkipEnv, NoopResetEnv\n",
    "# To construct vectorized environments\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "# To do frame stacking with vectorized environments\n",
    "from stable_baselines3.common.vec_env import VecFrameStack"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Custom wrapper to apply multiple wrappers to the environment\n",
    "class SuperMarioBrosWrapper(gym.Wrapper):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            _env: gym.Env,\n",
    "            env_id: str,\n",
    "            actions_list: list\n",
    "    ):\n",
    "        # Create the game environment with OpenAI Gym from the NES-py rom\n",
    "        _env = gym_super_mario_bros.make(env_id)\n",
    "        # Enable actions in the actions list\n",
    "        _env = JoypadSpace(_env, actions_list)\n",
    "        # Resize the observation space to a square\n",
    "        _env = ResizeObservation(_env, (84, 84))\n",
    "        # Convert the image observation from RGB to gray scale\n",
    "        _env = GrayScaleObservation(_env, keep_dim=True)\n",
    "        # Set the maximum value of no operation to run to 30\n",
    "        _env = NoopResetEnv(_env)\n",
    "        # Return only every 4-th frame (frame skipping)\n",
    "        _env = MaxAndSkipEnv(_env)\n",
    "        # Clips the reward to {+1, 0, -1} by its sign.\n",
    "        _env = ClipRewardEnv(_env)\n",
    "\n",
    "        super().__init__(_env)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "5cbdb8aa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.1 - Play a game with random actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dfff4d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "# Wrap the environment to enable the list of SIMPLE_MOVEMENT actions\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f302acb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Display the meanings of all possible actions\n",
    "env.get_action_meanings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d91626a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reset the environment\n",
    "obs = env.reset()\n",
    "done = False\n",
    "score = 0\n",
    "\n",
    "while not done:\n",
    "    # Choose a random action among available actions\n",
    "    action = env.action_space.sample()\n",
    "    # Perform an action in the environment\n",
    "    # It returns :\n",
    "    #   the observation of the current environment\n",
    "    #   the amount of reward returned after previous action\n",
    "    #   the done boolean which is true whether the episode has ended\n",
    "    #   the info dictionary contains auxiliary diagnostic information\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    # Update the overall score with reward of the performed action\n",
    "    score += reward\n",
    "\n",
    "print(f'Score : {score}')\n",
    "\n",
    "# Close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcf3e45",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.2 - Stack frames to represent movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b056684",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the game environment\n",
    "# Preprocess to the environment for Super Mario Bros game\n",
    "# Enable Mario to do simple movements to the right and left\n",
    "# Vectorize the environment\n",
    "env = make_vec_env(SuperMarioBrosEnv,\n",
    "                   wrapper_class=SuperMarioBrosWrapper,\n",
    "                   wrapper_kwargs={'env_id': 'SuperMarioBros-v0',\n",
    "                                   'actions_list': SIMPLE_MOVEMENT})\n",
    "# Stack the last 4 frames of the game to have a dimension of movement\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480ede43",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "# Perform 10 actions and show them to visualize how the frame stacking works\n",
    "for i in range(10):\n",
    "    plt.figure(figsize=(20, 16))\n",
    "\n",
    "    # Print 4 images which represents the frames stacked in the environment\n",
    "    for idx in range(obs.shape[3]):\n",
    "        plt.subplot(1, 4, idx + 1)\n",
    "        plt.imshow(obs[0][:, :, idx])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step([action])\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47c740e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2 - Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Stable Baselines3 (SB3) : set of reliable implementations of reinforcement learning algorithms in PyTorch\n",
    "# Quantile Regression Deep Q-Network algorithm\n",
    "from sb3_contrib import QRDQN\n",
    "# Proximal Policy Optimization algorithm\n",
    "from stable_baselines3 import PPO\n",
    "# To save and evaluate regularly a model during training\n",
    "from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback, EvalCallback\n",
    "# To evaluate a model\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "# To give linear function to hyperparams (e.g. learning rate, clip range, ...)\n",
    "from stable_baselines3.common.type_aliases import Schedule"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to make a value follow a linear evolution\n",
    "def linear_schedule(initial_value: float) -> Schedule:\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        return progress_remaining * initial_value\n",
    "\n",
    "    return func"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "3a6de994",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.1 - Setup train and evaluation environments with [RIGHT_ONLY actions](https://github.com/Kautenja/gym-super-mario-bros/blob/4c89cf601929733800f70833c7fe62973aecdb08/gym_super_mario_bros/actions.py#L5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14165b2d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create 8 vectorized environments\n",
    "# Wrap the environments to do some preprocessing\n",
    "# Enable Mario to do only movements to the right\n",
    "env = make_vec_env(SuperMarioBrosEnv,\n",
    "                   n_envs=8,\n",
    "                   wrapper_class=SuperMarioBrosWrapper,\n",
    "                   wrapper_kwargs={'env_id': 'SuperMarioBros-v0',\n",
    "                                   'actions_list': RIGHT_ONLY})\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea351d2e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_env = make_vec_env(SuperMarioBrosEnv,\n",
    "                        wrapper_class=SuperMarioBrosWrapper,\n",
    "                        wrapper_kwargs={'env_id': 'SuperMarioBros-v0',\n",
    "                                        'actions_list': RIGHT_ONLY})\n",
    "eval_env = VecFrameStack(eval_env, n_stack=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3cf25f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.2 - Setup checkpoint and evaluation callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7ab1db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a checkpoint callback to save the model every million steps\n",
    "# The save frequency refers to each environment (125 000 * 8 = 1 000 000)\n",
    "checkpoint_callback = CheckpointCallback(save_freq=125_000,\n",
    "                                         save_path='logs/',\n",
    "                                         name_prefix='super_mario_bros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8010f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create an evaluation callback to mesure the evolution of the model every hundred thousand steps\n",
    "# The evaluation frequency refers to each environment (12 500 * 8 = 100 000)\n",
    "eval_callback = EvalCallback(eval_env,\n",
    "                             best_model_save_path='logs/',\n",
    "                             eval_freq=12_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f309b32",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of callbacks to give it at the initialization of the model learning\n",
    "callback_list = CallbackList([checkpoint_callback, eval_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685012b4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.3 - Train a model with [PPO algorithm](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb047b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_callback.name_prefix = 'right_only/ppo/super_mario_bros'\n",
    "eval_callback.best_model_save_path = 'logs/right_only/ppo/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ae481",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the model with atari hyperparams from https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/ppo.yml\n",
    "# Hyperparams are the following :\n",
    "#   - CnnPolicy : Convolutional Neural Network policy class for actor-critic algorithms\n",
    "#   - env : 8 vectorized environments with 4 frames stacked each\n",
    "#   - learning_rate=linear_schedule(2.5e-4) : learning rate function of the current progress remaining (from 1 to 0)\n",
    "#   - n_steps=128 : number of steps to run for each environment per update\n",
    "#   - batch_size=256 : Minibatch size (where batch size is n_steps times the number of environment copies running in parallel)\n",
    "#   - n_epochs=4 : number of epoch when optimizing the surrogate loss\n",
    "#   - clip_range=linear_schedule(0.1) : clipping function of the current progress remaining (from 1 to 0)\n",
    "#   - ent_coef=0.01 : entropy coefficient for the loss calculation\n",
    "#   - vf_coef=0.5 : value function coefficient for the loss calculation\n",
    "#   - verbose=1 : the verbosity level: 0 no output, 1 info, 2 debug\n",
    "#   - tensorboard_log='logs/tensorboard/' : the log location for tensorboard\n",
    "model = PPO('CnnPolicy',\n",
    "            env,\n",
    "            learning_rate=linear_schedule(2.5e-4),\n",
    "            n_steps=128,\n",
    "            batch_size=256,\n",
    "            n_epochs=4,\n",
    "            clip_range=linear_schedule(0.1),\n",
    "            ent_coef=0.01,\n",
    "            vf_coef=0.5,\n",
    "            verbose=1,\n",
    "            tensorboard_log='logs/tensorboard/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6fd724",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model, execute callbacks and log to follow the evolution with tensorboard\n",
    "model.learn(total_timesteps=int(5e6),\n",
    "            callback=callback_list,\n",
    "            log_interval=100,\n",
    "            tb_log_name='right_only_ppo_super_mario_bros')\n",
    "# Save the model in a zip file\n",
    "model.save('right_only_ppo_super_mario_bros')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac341a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.4 - Trained a model with [QR-DQN algorithm](https://sb3-contrib.readthedocs.io/en/master/modules/qrdqn.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca00b1ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_callback.name_prefix = 'right_only/qrdqn/super_mario_bros'\n",
    "eval_callback.best_model_save_path = 'logs/right_only/qrdqn/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e6ffff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the model with atari hyperparams from https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/qrdqn.yml\n",
    "# Hyperparams are the following :\n",
    "#   - CnnPolicy : the policy class for QR-DQN when using images as input\n",
    "#   - env : 8 vectorized environments with 4 frames stacked each\n",
    "#   - optimize_memory_usage=True : enable a memory efficient variant of the replay buffer at a cost of more complexity\n",
    "#   - exploration_fraction=0.025 : fraction of entire training period over which the exploration rate is reduced\n",
    "#   - verbose=1 : the verbosity level: 0 no output, 1 info, 2 debug\n",
    "#   - tensorboard_log='logs/tensorboard/' : the log location for tensorboard\n",
    "model = QRDQN('CnnPolicy',\n",
    "              env,\n",
    "              optimize_memory_usage=True,\n",
    "              exploration_fraction=0.025,\n",
    "              verbose=1,\n",
    "              tensorboard_log='logs/tensorboard/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18310b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=int(5e6),\n",
    "            callback=callback_list,\n",
    "            log_interval=2000,\n",
    "            tb_log_name='right_only_qrdqn_super_mario_bros')\n",
    "model.save('right_only_qrdqn_super_mario_bros')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8041b9a4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.5 - Setup train and evaluation environments with [SIMPLE_MOVEMENT actions](https://github.com/Kautenja/gym-super-mario-bros/blob/4c89cf601929733800f70833c7fe62973aecdb08/gym_super_mario_bros/actions.py#L15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3baeb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env = make_vec_env(SuperMarioBrosEnv,\n",
    "                   wrapper_class=SuperMarioBrosWrapper,\n",
    "                   wrapper_kwargs={'env_id': 'SuperMarioBros-v0',\n",
    "                                   'actions_list': SIMPLE_MOVEMENT})\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5985db55",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_env = make_vec_env(SuperMarioBrosEnv,\n",
    "                        wrapper_class=SuperMarioBrosWrapper,\n",
    "                        wrapper_kwargs={'env_id': 'SuperMarioBros-v0',\n",
    "                                        'actions_list': SIMPLE_MOVEMENT})\n",
    "eval_env = VecFrameStack(eval_env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed5c6d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_callback.eval_env = eval_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5559102e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.6 - Train a model with [PPO algorithm](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d7994",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_callback.name_prefix = 'simple_movement/ppo/super_mario_bros'\n",
    "eval_callback.best_model_save_path = 'logs/simple_movement/ppo/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d65b46",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = PPO('CnnPolicy',\n",
    "            env,\n",
    "            learning_rate=linear_schedule(2.5e-4),\n",
    "            n_steps=128,\n",
    "            batch_size=256,\n",
    "            n_epochs=4,\n",
    "            clip_range=linear_schedule(0.1),\n",
    "            ent_coef=0.01,\n",
    "            vf_coef=0.5,\n",
    "            verbose=1,\n",
    "            tensorboard_log='logs/tensorboard/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98325bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=int(3e6),\n",
    "            callback=callback_list,\n",
    "            log_interval=100,\n",
    "            tb_log_name='simple_movement_ppo_super_mario_bros')\n",
    "model.save('simple_movement_ppo_super_mario_bros')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd4ce87",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.7 - Trained a model with [QR-DQN algorithm](https://sb3-contrib.readthedocs.io/en/master/modules/qrdqn.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d1256f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_callback.name_prefix = 'simple_movement/qrdqn/super_mario_bros'\n",
    "eval_callback.best_model_save_path = 'logs/simple_movement/qrdqn/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5585983c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = QRDQN('CnnPolicy',\n",
    "              env,\n",
    "              optimize_memory_usage=True,\n",
    "              exploration_fraction=0.025,\n",
    "              verbose=1,\n",
    "              tensorboard_log='logs/tensorboard/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94ccda",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=int(3e6),\n",
    "            callback=callback_list,\n",
    "            log_interval=2000,\n",
    "            tb_log_name='simple_movement_qrdqn_super_mario_bros')\n",
    "model.save('simple_movement_qrdqn_super_mario_bros')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e56923c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3 - See the results of trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f422a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Function to evaluate a model on an environment and render the played game\n",
    "def demo(_model, _env):\n",
    "    mean_reward, std_reward = evaluate_policy(_model, _env, render=True)\n",
    "    print(f'mean_reward = {mean_reward:.2f} +/- {std_reward:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d9e381",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.1 - Setup the demonstration environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038029c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "right_only_demo_env = make_vec_env(SuperMarioBrosEnv,\n",
    "                                   wrapper_class=SuperMarioBrosWrapper,\n",
    "                                   wrapper_kwargs={'env_id': 'SuperMarioBros-v0',\n",
    "                                                   'actions_list': RIGHT_ONLY})\n",
    "right_only_demo_env = VecFrameStack(right_only_demo_env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ebd391",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "simple_movement_demo_env = make_vec_env(SuperMarioBrosEnv,\n",
    "                                        wrapper_class=SuperMarioBrosWrapper,\n",
    "                                        wrapper_kwargs={'env_id': 'SuperMarioBros-v0',\n",
    "                                                        'actions_list': SIMPLE_MOVEMENT})\n",
    "simple_movement_demo_env = VecFrameStack(simple_movement_demo_env, n_stack=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fad531",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.2 - Demo of models trained with [PPO algorithm](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e311d68e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2.1 - Environment with [RIGHT_ONLY actions](https://github.com/Kautenja/gym-super-mario-bros/blob/4c89cf601929733800f70833c7fe62973aecdb08/gym_super_mario_bros/actions.py#L5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85934c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the model with a saved zip file\n",
    "demo_model = PPO.load('logs/right_only/ppo/best_model')\n",
    "demo(demo_model, right_only_demo_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f8be81",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "demo_model = PPO.load('right_only_ppo_super_mario_bros')\n",
    "demo(demo_model, right_only_demo_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ce578",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2.2 - Environment with [SIMPLE_MOVEMENT actions](https://github.com/Kautenja/gym-super-mario-bros/blob/4c89cf601929733800f70833c7fe62973aecdb08/gym_super_mario_bros/actions.py#L15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff5cfd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "demo_model = PPO.load('logs/simple_movement/ppo/best_model')\n",
    "demo(demo_model, simple_movement_demo_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81af720e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "demo_model = PPO.load('simple_movement_ppo_super_mario_bros')\n",
    "demo(demo_model, simple_movement_demo_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0999fce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.3 - Demo of models trained with [QR-DQN algorithm](https://sb3-contrib.readthedocs.io/en/master/modules/qrdqn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8301f39",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.3.1 - Environment with [RIGHT_ONLY actions](https://github.com/Kautenja/gym-super-mario-bros/blob/4c89cf601929733800f70833c7fe62973aecdb08/gym_super_mario_bros/actions.py#L5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56615b9f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "demo_model = QRDQN.load('logs/right_only/qrdqn/best_model')\n",
    "demo(demo_model, right_only_demo_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e0678",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "demo_model = QRDQN.load('right_only_qrdqn_super_mario_bros')\n",
    "demo(demo_model, right_only_demo_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215557fa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.3.2 - Environment with [SIMPLE_MOVEMENT actions](https://github.com/Kautenja/gym-super-mario-bros/blob/4c89cf601929733800f70833c7fe62973aecdb08/gym_super_mario_bros/actions.py#L15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc883ce3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "demo_model = QRDQN.load('logs/simple_movement/qrdqn/best_model')\n",
    "demo(demo_model, simple_movement_demo_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d27b839",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "demo_model = QRDQN.load('simple_movement_qrdqn_super_mario_bros')\n",
    "demo(demo_model, simple_movement_demo_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51c59d3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Bonus - Make a gif of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gif_env = make_vec_env(SuperMarioBrosEnv,\n",
    "                       wrapper_class=SuperMarioBrosWrapper,\n",
    "                       wrapper_kwargs={'env_id': 'SuperMarioBros-v0',\n",
    "                                       'actions_list': RIGHT_ONLY})\n",
    "gif_env = VecFrameStack(gif_env, n_stack=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gif_model = QRDQN.load('right_only_qrdqn_super_mario_bros')\n",
    "gif_model.set_env(gif_env)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.mkdir('tmp')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://stable-baselines3.readthedocs.io/en/master/guide/examples.html#bonus-make-a-gif-of-a-trained-agent\n",
    "images = []\n",
    "obs = gif_env.reset()\n",
    "img = gif_env.render(mode='rgb_array')\n",
    "\n",
    "for i in range(350):\n",
    "    images.append(img)\n",
    "    action, _ = gif_model.predict(obs)\n",
    "    obs, _, _, _ = gif_env.step(action)\n",
    "    img = gif_env.render(mode='rgb_array')\n",
    "    plt.imsave(f'tmp/{i}.jpg', img)\n",
    "\n",
    "gif_env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imageio.mimsave('../images/super_mario_bros3.gif',\n",
    "                np.stack([imageio.v3.imread(f'tmp/{i}.jpg') for i, img in enumerate(images) if i % 2 == 0]),\n",
    "                fps=29)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shutil.rmtree('tmp')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
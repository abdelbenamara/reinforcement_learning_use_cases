{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28a4542",
   "metadata": {},
   "source": [
    "# ROBOTIC\n",
    "\n",
    "Using stable_baselines3 for robotic use case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa030acc",
   "metadata": {},
   "source": [
    "## 1. Importing dependancy\n",
    "\n",
    "* **gym** : Environnments library for reinforcement learning\n",
    "* **panda-gym** : Open source library for robotic environnment using pybullet\n",
    "* **stable_baselines3** : reinforcement learning library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec69ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import panda_gym\n",
    "import stable_baselines3\n",
    "from stable_baselines3.common.logger import configure\n",
    "from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback, EvalCallback\n",
    "from stable_baselines3 import HerReplayBuffer, DDPG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dda8f9",
   "metadata": {},
   "source": [
    "## 2. Testing the environnment with random variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c35f608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('PandaPush-v2', render=True) # Create the environmment with a view\n",
    "\n",
    "obs = env.reset() # reset the environnment\n",
    "done = False\n",
    "\n",
    "while not done: \n",
    "    action = env.action_space.sample() # random action\n",
    "    obs, reward, done, info = env.step(action)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9820e680",
   "metadata": {},
   "source": [
    "## 3. Setting up model with [HER](https://stable-baselines3.readthedocs.io/en/master/modules/her.html) : [DDPG](https://stable-baselines3.readthedocs.io/en/master/modules/ddpg.html)\n",
    "Setting the model hyper-parameters from community data :https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/her.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8dbf79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"PandaPush-v2\") # Create the environnment with no rendering\n",
    "model = DDPG('MultiInputPolicy', \n",
    "             env, \n",
    "             replay_buffer_class=HerReplayBuffer, \n",
    "             replay_buffer_kwargs=dict(\n",
    "                 n_sampled_goal=4,\n",
    "                 goal_selection_strategy='future',\n",
    "                 online_sampling=True,\n",
    "             ), \n",
    "             buffer_size = 1000000, \n",
    "             tau = 0.05, \n",
    "             learning_rate = 1e-3, \n",
    "             verbose=1, \n",
    "             batch_size = 2048, \n",
    "             gamma = 0.95, \n",
    "             policy_kwargs = dict(\n",
    "                 n_critics=2, \n",
    "                 net_arch=[512, 512, 512]\n",
    "             ), \n",
    "             tensorboard_log=\"logs/tensorboard/\") # Create a model with sepcify hyper-parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d88e2fa",
   "metadata": {},
   "source": [
    "### 3.1. Setting callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcb5ca9",
   "metadata": {},
   "source": [
    "**Saving a version of the model each 1000 steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5264c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = CheckpointCallback(save_freq=1000, \n",
    "                                         save_path='.', \n",
    "                                         name_prefix='PandaPush-v2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a078f7",
   "metadata": {},
   "source": [
    "**Evaluate the model each 1000 steps and save it as \"best_model\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8d63b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_callback = EvalCallback(env, \n",
    "                             best_model_save_path='logs/DDPG', \n",
    "                             eval_freq=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7002b2",
   "metadata": {},
   "source": [
    "**Putting the callbacks in a list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a440e2cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "callback_list = CallbackList([checkpoint_callback, eval_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5982d6",
   "metadata": {},
   "source": [
    "## 4. Training the model\n",
    "* For 10000 steps\n",
    "* Logging the state of the model each 1000 steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896dfaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=10000, \n",
    "            callback=callback_list, \n",
    "            log_interval=1000, \n",
    "            tb_log_name='logs_robotics_PandaPush')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a389223a",
   "metadata": {},
   "source": [
    "## 5 Saving and cleaning the environnment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a6505",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"PandaPush-v2-model\") # Saving the model\n",
    "\n",
    "del model #cleaning\n",
    "del env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3b624",
   "metadata": {},
   "source": [
    "## 6 Testing the environnment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f46e06b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"PandaPush-v2\", render=True) # creating the environnment with rendering\n",
    "model = DDPG.load(\"PandaPush-v2-model\", env=env) # load the best version of the model\n",
    "obs = env.reset()\n",
    "dones = False\n",
    "\n",
    "while not dones:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e1cb3",
   "metadata": {},
   "source": [
    "## 7. Testing community trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f921fe70",
   "metadata": {},
   "source": [
    "### 7.1 import sb3_contrib dependancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a761528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panda_gym\n",
    "from sb3_contrib import TQC\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from sb3_contrib.common.wrappers import TimeFeatureWrapper\n",
    "from stable_baselines3.common.logger import configure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82872c94",
   "metadata": {},
   "source": [
    "### 7.2 loading and running community trained model with [TQC](https://sb3-contrib.readthedocs.io/en/master/modules/tqc.html) model\n",
    "\n",
    "Since training a robotic model demands a lot of computing power we were not able to creat a satisfying model. Let's try one model given by the community throught sb3_contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836fcd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_vec_env(\"PandaPush-v2\", wrapper_class=TimeFeatureWrapper, env_kwargs={'render':True})\n",
    "model = TQC.load(\"logs/TQC/PandaPush-v1\", custom_objects={'learning_rate':0.001}, env=env)\n",
    "obs = env.reset()\n",
    "dones = False\n",
    "while not dones:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f163d540",
   "metadata": {},
   "source": [
    "## 8. Creating GIF\n",
    "\n",
    "Exporting a gif of the environnment with the model taken from community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy\n",
    "\n",
    "gif_env = make_vec_env(\"PandaPush-v2\", wrapper_class=TimeFeatureWrapper, env_kwargs={'render':True})\n",
    "gif_model = TQC.load(\"logs/TQC/PandaPush-v1\", custom_objects={'learning_rate':0.001}, env=gif_env)\n",
    "images = []\n",
    "obs = gif_env.reset()\n",
    "img = gif_env.render(mode='rgb_array')\n",
    "\n",
    "for i in range(350):\n",
    "    images.append(img)\n",
    "    action, _ = gif_model.predict(obs)\n",
    "    obs, _, _, _ = gif_env.step(action)\n",
    "    img = gif_env.render(mode='rgb_array')\n",
    "\n",
    "imageio.mimsave('test_panda_push.gif',\n",
    "                [numpy.array(img) for i, img in enumerate(images) if i % 2 == 0],\n",
    "                fps=29)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28a4542",
   "metadata": {},
   "source": [
    "# ROBOTIC\n",
    "\n",
    "Using stable_baselines3 for robotic use case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5017657f",
   "metadata": {},
   "source": [
    "### pip install\n",
    "\n",
    "Installing gym and panda-gym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffed3cca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines3\n",
      "  Using cached stable_baselines3-1.5.0-py3-none-any.whl (177 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.22.3-cp38-cp38-macosx_10_14_x86_64.whl (17.6 MB)\n",
      "Collecting cloudpickle\n",
      "  Using cached cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
      "Collecting gym==0.21\n",
      "  Using cached gym-0.21.0-py3-none-any.whl\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.5.2-cp38-cp38-macosx_10_9_x86_64.whl (7.3 MB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.4.2-cp38-cp38-macosx_10_9_x86_64.whl (11.0 MB)\n",
      "Collecting torch>=1.8.1\n",
      "  Using cached torch-1.11.0-cp38-none-macosx_10_9_x86_64.whl (129.9 MB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.2-cp38-cp38-macosx_10_9_x86_64.whl (65 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-9.1.0-cp38-cp38-macosx_10_9_x86_64.whl (3.1 MB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3) (3.0.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3) (21.3)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
      "Installing collected packages: pytz, typing-extensions, pillow, numpy, kiwisolver, fonttools, cycler, cloudpickle, torch, pandas, matplotlib, gym, stable-baselines3\n",
      "Successfully installed cloudpickle-2.0.0 cycler-0.11.0 fonttools-4.33.3 gym-0.21.0 kiwisolver-1.4.2 matplotlib-3.5.2 numpy-1.22.3 pandas-1.4.2 pillow-9.1.0 pytz-2022.1 stable-baselines3-1.5.0 torch-1.11.0 typing-extensions-4.2.0\n",
      "Collecting panda-gym\n",
      "  Using cached panda_gym-2.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: gym in ./venv/lib/python3.8/site-packages (from panda-gym) (0.21.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.8/site-packages (from panda-gym) (1.22.3)\n",
      "Collecting pybullet\n",
      "  Using cached pybullet-3.2.4-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "Collecting gym-robotics\n",
      "  Using cached gym_robotics-0.1.0-py3-none-any.whl\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.8.0-cp38-cp38-macosx_12_0_universal2.macosx_10_9_x86_64.whl (55.3 MB)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./venv/lib/python3.8/site-packages (from gym->panda-gym) (2.0.0)\n",
      "Collecting gym\n",
      "  Using cached gym-0.23.1-py3-none-any.whl\n",
      "Collecting importlib-metadata>=4.10.0\n",
      "  Using cached importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Using cached gym_notices-0.0.6-py3-none-any.whl (2.7 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.8/site-packages (from importlib-metadata>=4.10.0->gym->panda-gym) (3.8.0)\n",
      "Installing collected packages: pybullet, gym-notices, scipy, importlib-metadata, gym, gym-robotics, panda-gym\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.21.0\n",
      "    Uninstalling gym-0.21.0:\n",
      "      Successfully uninstalled gym-0.21.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "stable-baselines3 1.5.0 requires gym==0.21, but you have gym 0.23.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed gym-0.23.1 gym-notices-0.0.6 gym-robotics-0.1.0 importlib-metadata-4.11.3 panda-gym-2.0.1 pybullet-3.2.4 scipy-1.8.0\n",
      "Collecting tensorboard\n",
      "  Using cached tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./venv/lib/python3.8/site-packages (from tensorboard) (62.1.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in ./venv/lib/python3.8/site-packages (from tensorboard) (1.22.3)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in ./venv/lib/python3.8/site-packages (from tensorboard) (0.37.1)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Using cached protobuf-3.20.1-cp38-cp38-macosx_10_9_x86_64.whl (962 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.44.0-cp38-cp38-macosx_10_10_x86_64.whl (4.3 MB)\n",
      "Requirement already satisfied: six in ./venv/lib/python3.8/site-packages (from absl-py>=0.4->tensorboard) (1.16.0)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./venv/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard) (4.11.3)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.8.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, certifi, werkzeug, urllib3, tensorboard-data-server, rsa, pyasn1-modules, protobuf, oauthlib, idna, grpcio, charset-normalizer, cachetools, absl-py, requests, markdown, google-auth, requests-oauthlib, google-auth-oauthlib, tensorboard\n",
      "Successfully installed absl-py-1.0.0 cachetools-5.0.0 certifi-2021.10.8 charset-normalizer-2.0.12 google-auth-2.6.6 google-auth-oauthlib-0.4.6 grpcio-1.44.0 idna-3.3 markdown-3.3.6 oauthlib-3.2.0 protobuf-3.20.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 urllib3-1.26.9 werkzeug-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3\n",
    "!pip install panda-gym\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa030acc",
   "metadata": {},
   "source": [
    "### import\n",
    "\n",
    "Importing gym and panda-gym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec69ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathieuridet/Documents/Paris1/M2/S2/DEC3 - Machine Learning/reinforcement_learning_use_cases/robotic/venv/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import panda_gym\n",
    "import stable_baselines3\n",
    "from stable_baselines3.common.logger import configure\n",
    "from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback, EvalCallback\n",
    "from stable_baselines3 import HerReplayBuffer, DDPG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dda8f9",
   "metadata": {},
   "source": [
    "## Testing the environnment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c35f608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('PandaPush-v2', render=True)\n",
    "\n",
    "obs = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = env.action_space.sample() # random action\n",
    "    obs, reward, done, info = env.step(action)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9820e680",
   "metadata": {},
   "source": [
    "### Setting up model\n",
    "Hyper-parameters from https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/her.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b8dbf79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"PandaPush-v2\")\n",
    "model = DDPG('MultiInputPolicy', \n",
    "             env, \n",
    "             replay_buffer_class=HerReplayBuffer, \n",
    "             replay_buffer_kwargs=dict(\n",
    "                 n_sampled_goal=4,\n",
    "                 goal_selection_strategy='future',\n",
    "                 online_sampling=True,\n",
    "             ), \n",
    "             buffer_size = 1000000, \n",
    "             tau = 0.05, \n",
    "             learning_rate = 1e-3, \n",
    "             verbose=1, \n",
    "             batch_size = 2048, \n",
    "             gamma = 0.95, \n",
    "             policy_kwargs = dict(\n",
    "                 n_critics=2, \n",
    "                 net_arch=[512, 512, 512]\n",
    "             ), \n",
    "             tensorboard_log=\"logs/tensorboard/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5982d6",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5264c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = CheckpointCallback(save_freq=1000, \n",
    "                                         save_path='.', \n",
    "                                         name_prefix='PandaPush-v1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db8d63b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_callback = EvalCallback(env, \n",
    "                             best_model_save_path='eval_save', \n",
    "                             eval_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a440e2cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs/tensorboard/logs_robotics_PandaPush_1\n",
      "Eval num_timesteps=1000, episode_reward=-40.00 +/- 20.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -40      |\n",
      "|    success_rate    | 0.2      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.947    |\n",
      "|    critic_loss     | 0.0543   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 850      |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=2000, episode_reward=-40.00 +/- 20.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -40      |\n",
      "|    success_rate    | 0.2      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 2000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.25     |\n",
      "|    critic_loss     | 0.063    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1850     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=3000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -50      |\n",
      "|    success_rate    | 0        |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 3000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.87     |\n",
      "|    critic_loss     | 0.19     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2850     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=-40.00 +/- 20.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -40      |\n",
      "|    success_rate    | 0.2      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.55     |\n",
      "|    critic_loss     | 0.0812   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3850     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-40.00 +/- 20.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -40      |\n",
      "|    success_rate    | 0.2      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 5000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.7      |\n",
      "|    critic_loss     | 0.0559   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4850     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -50      |\n",
      "|    success_rate    | 0        |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 6000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.15     |\n",
      "|    critic_loss     | 0.0568   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5850     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=7000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -50      |\n",
      "|    success_rate    | 0        |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 7000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.36     |\n",
      "|    critic_loss     | 0.118    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6850     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -50      |\n",
      "|    success_rate    | 0        |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.57     |\n",
      "|    critic_loss     | 0.0523   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7850     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=9000, episode_reward=-40.00 +/- 20.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -40      |\n",
      "|    success_rate    | 0.2      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 9000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.54     |\n",
      "|    critic_loss     | 0.0712   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8850     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -50      |\n",
      "|    success_rate    | 0        |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.54     |\n",
      "|    critic_loss     | 0.094    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9850     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ddpg.ddpg.DDPG at 0x7fc4093f9eb0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_list = CallbackList([checkpoint_callback, eval_callback])\n",
    "\n",
    "model.learn(total_timesteps=10000, \n",
    "            callback=callback_list, \n",
    "            log_interval=1000, \n",
    "            tb_log_name='logs_robotics_PandaPush')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a389223a",
   "metadata": {},
   "source": [
    "### Saving and cleaning the environnment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "057a6505",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"PandaPush-v2-DDPG\")\n",
    "\n",
    "del model\n",
    "del env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3b624",
   "metadata": {},
   "source": [
    "### Testing the environnment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f46e06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 09:36:30.424 Python[38148:1933253] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to /var/folders/4j/sm6ccfnj0xs0g2nm3mnz28540000gn/T/org.python.python.savedState\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"PandaPush-v2\", render=True)\n",
    "model = DDPG.load(\"PandaPush-v2-DDPG\", env=env)\n",
    "obs = env.reset()\n",
    "dones = False\n",
    "\n",
    "while not dones:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2a196a",
   "metadata": {},
   "source": [
    "### installing sb3-contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a34262",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sb3-contrib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e1cb3",
   "metadata": {},
   "source": [
    "### Testing community trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a761528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panda_gym\n",
    "from sb3_contrib import TQC\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from sb3_contrib.common.wrappers import TimeFeatureWrapper\n",
    "from stable_baselines3.common.logger import configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836fcd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_vec_env(\"PandaPush-v2\", wrapper_class=TimeFeatureWrapper, env_kwargs={'render':True})\n",
    "model = TQC.load(\"PandaPush-v1\", custom_objects={'learning_rate':0.001}, env=env)\n",
    "obs = env.reset()\n",
    "dones = False\n",
    "while not dones:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

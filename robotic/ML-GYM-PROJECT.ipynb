{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28a4542",
   "metadata": {},
   "source": [
    "# ROBOTIC\n",
    "\n",
    "Using stable_baselines3 for robotic use case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa030acc",
   "metadata": {},
   "source": [
    "## 1. Importing dependancy\n",
    "\n",
    "* **gym** : Environnments library for reinforcement learning\n",
    "* **panda-gym** : Open source library for robotic environnment using pybullet\n",
    "* **stable_baselines3** : reinforcement learning library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec69ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathieuridet/Documents/Paris1/M2/S2/DEC3 - Machine Learning/reinforcement_learning_use_cases/robotic/venv/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import panda_gym\n",
    "import stable_baselines3\n",
    "from stable_baselines3.common.logger import configure\n",
    "from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback, EvalCallback\n",
    "from stable_baselines3 import HerReplayBuffer, DDPG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dda8f9",
   "metadata": {},
   "source": [
    "## 2. Testing the environnment with random variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c35f608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Apr 26 2022 03:13:28\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('PandaPush-v2', render=True) # Create the environmment with a view\n",
    "\n",
    "obs = env.reset() # reset the environnment\n",
    "done = False\n",
    "\n",
    "while not done: \n",
    "    action = env.action_space.sample() # random action\n",
    "    obs, reward, done, info = env.step(action)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9820e680",
   "metadata": {},
   "source": [
    "## 3. Setting up model with [HER](https://stable-baselines3.readthedocs.io/en/master/modules/her.html) : [DDPG](https://stable-baselines3.readthedocs.io/en/master/modules/ddpg.html)\n",
    "Setting the model hyper-parameters from community data :https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/her.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b8dbf79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: May  3 2022 14:33:20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"PandaPush-v2\") # Create the environnment with no rendering\n",
    "model = DDPG('MultiInputPolicy', \n",
    "             env, \n",
    "             replay_buffer_class=HerReplayBuffer, \n",
    "             replay_buffer_kwargs=dict(\n",
    "                 n_sampled_goal=4,\n",
    "                 goal_selection_strategy='future',\n",
    "                 online_sampling=True,\n",
    "             ), \n",
    "             buffer_size = 1000000, \n",
    "             tau = 0.05, \n",
    "             learning_rate = 1e-3, \n",
    "             verbose=1, \n",
    "             batch_size = 2048, \n",
    "             gamma = 0.95, \n",
    "             policy_kwargs = dict(\n",
    "                 n_critics=2, \n",
    "                 net_arch=[512, 512, 512]\n",
    "             ), \n",
    "             tensorboard_log=\"logs/tensorboard/\") # Create a model with sepcify hyper-parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d88e2fa",
   "metadata": {},
   "source": [
    "### 3.1. Setting callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcb5ca9",
   "metadata": {},
   "source": [
    "**Saving a version of the model each 1000 steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5264c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = CheckpointCallback(save_freq=1000, \n",
    "                                         save_path='.', \n",
    "                                         name_prefix='PandaPush-v2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a078f7",
   "metadata": {},
   "source": [
    "**Evaluate the model each 1000 steps and save it as \"best_model\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db8d63b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_callback = EvalCallback(env, \n",
    "                             best_model_save_path='logs/DDPG', \n",
    "                             eval_freq=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7002b2",
   "metadata": {},
   "source": [
    "**Putting the callbacks in a list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a440e2cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "callback_list = CallbackList([checkpoint_callback, eval_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5982d6",
   "metadata": {},
   "source": [
    "## 4. Training the model\n",
    "* For 10000 steps\n",
    "* Logging the state of the model each 1000 steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "896dfaa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs/tensorboard/logs_robotics_PandaPush_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathieuridet/Documents/Paris1/M2/S2/DEC3 - Machine Learning/reinforcement_learning_use_cases/robotic/venv/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1000, episode_reward=-40.00 +/- 20.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -40      |\n",
      "|    success_rate    | 0.2      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.93     |\n",
      "|    critic_loss     | 0.0372   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 850      |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=2000, episode_reward=-40.00 +/- 20.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -40      |\n",
      "|    success_rate    | 0.2      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 2000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.5      |\n",
      "|    critic_loss     | 0.055    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1850     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=3000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -50      |\n",
      "|    success_rate    | 0        |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 3000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.8      |\n",
      "|    critic_loss     | 0.0497   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2850     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=-40.00 +/- 20.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -40      |\n",
      "|    success_rate    | 0.2      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.31     |\n",
      "|    critic_loss     | 0.0534   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3850     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -50      |\n",
      "|    success_rate    | 0        |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 5000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.56     |\n",
      "|    critic_loss     | 0.0805   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4850     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -50      |\n",
      "|    success_rate    | 0        |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 6000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.37     |\n",
      "|    critic_loss     | 0.0507   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5850     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=7000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -50      |\n",
      "|    success_rate    | 0        |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 7000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.46     |\n",
      "|    critic_loss     | 0.0444   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6850     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -50      |\n",
      "|    success_rate    | 0        |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.46     |\n",
      "|    critic_loss     | 0.162    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7850     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=9000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -50      |\n",
      "|    success_rate    | 0        |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 9000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.85     |\n",
      "|    critic_loss     | 0.166    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8850     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 50       |\n",
      "|    mean_reward     | -50      |\n",
      "|    success_rate    | 0        |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.87     |\n",
      "|    critic_loss     | 0.0851   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9850     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ddpg.ddpg.DDPG at 0x7f84caf255e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=10000, \n",
    "            callback=callback_list, \n",
    "            log_interval=1000, \n",
    "            tb_log_name='logs_robotics_PandaPush')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a389223a",
   "metadata": {},
   "source": [
    "## 5 Saving and cleaning the environnment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "057a6505",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"PandaPush-v2-model\") # Saving the model\n",
    "\n",
    "del model #cleaning\n",
    "del env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3b624",
   "metadata": {},
   "source": [
    "## 6 Testing the environnment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f46e06b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argv[0]=--background_color_red=0.8745098039215686\n",
      "argv[1]=\n",
      "argv[2]=\n",
      "argv[3]=\n",
      "argv[4]=\n",
      "argv[5]=\n",
      "argv[6]=\n",
      "argv[7]=\n",
      "argv[8]=\n",
      "argv[9]=\n",
      "argv[10]=\n",
      "argv[11]=\n",
      "argv[12]=\n",
      "argv[13]=\n",
      "argv[14]=\n",
      "argv[15]=\n",
      "argv[16]=\n",
      "argv[17]=\n",
      "argv[18]=\n",
      "argv[19]=\n",
      "argv[20]=\n",
      "argv[21]=--background_color_green=0.21176470588235294\n",
      "argv[22]=\n",
      "argv[23]=\n",
      "argv[24]=\n",
      "argv[25]=\n",
      "argv[26]=\n",
      "argv[27]=\n",
      "argv[28]=\n",
      "argv[29]=\n",
      "argv[30]=\n",
      "argv[31]=\n",
      "argv[32]=\n",
      "argv[33]=\n",
      "argv[34]=\n",
      "argv[35]=\n",
      "argv[36]=\n",
      "argv[37]=\n",
      "argv[38]=\n",
      "argv[39]=\n",
      "argv[40]=\n",
      "argv[41]=\n",
      "argv[42]=--background_color_blue=0.17647058823529413\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=45\n",
      "argv[0] = --unused\n",
      "argv[1] = --background_color_red=0.8745098039215686\n",
      "argv[2] = \n",
      "argv[3] = \n",
      "argv[4] = \n",
      "argv[5] = \n",
      "argv[6] = \n",
      "argv[7] = \n",
      "argv[8] = \n",
      "argv[9] = \n",
      "argv[10] = \n",
      "argv[11] = \n",
      "argv[12] = \n",
      "argv[13] = \n",
      "argv[14] = \n",
      "argv[15] = \n",
      "argv[16] = \n",
      "argv[17] = \n",
      "argv[18] = \n",
      "argv[19] = \n",
      "argv[20] = \n",
      "argv[21] = \n",
      "argv[22] = --background_color_green=0.21176470588235294\n",
      "argv[23] = \n",
      "argv[24] = \n",
      "argv[25] = \n",
      "argv[26] = \n",
      "argv[27] = \n",
      "argv[28] = \n",
      "argv[29] = \n",
      "argv[30] = \n",
      "argv[31] = \n",
      "argv[32] = \n",
      "argv[33] = \n",
      "argv[34] = \n",
      "argv[35] = \n",
      "argv[36] = \n",
      "argv[37] = \n",
      "argv[38] = \n",
      "argv[39] = \n",
      "argv[40] = \n",
      "argv[41] = \n",
      "argv[42] = \n",
      "argv[43] = --background_color_blue=0.17647058823529413\n",
      "argv[44] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Intel\n",
      "GL_RENDERER=Mesa Intel(R) HD Graphics 620 (KBL GT2)\n",
      "GL_VERSION=4.6 (Core Profile) Mesa 21.2.6\n",
      "GL_SHADING_LANGUAGE_VERSION=4.60\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.6 (Core Profile) Mesa 21.2.6\n",
      "Vendor = Intel\n",
      "Renderer = Mesa Intel(R) HD Graphics 620 (KBL GT2)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "numActiveThreads = 0\n",
      "stopping threads\n",
      "Thread with taskId 0 exiting\n",
      "Thread TERMINATED\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n",
      "finished\n",
      "numActiveThreads = 0\n",
      "btShutDownExampleBrowser stopping threads\n",
      "Thread with taskId 0 exiting\n",
      "Thread TERMINATED\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n",
      "argv[0]=--background_color_red=0.8745098039215686\n",
      "argv[1]=\n",
      "argv[2]=\n",
      "argv[3]=\n",
      "argv[4]=\n",
      "argv[5]=\n",
      "argv[6]=\n",
      "argv[7]=\n",
      "argv[8]=\n",
      "argv[9]=\n",
      "argv[10]=\n",
      "argv[11]=\n",
      "argv[12]=\n",
      "argv[13]=\n",
      "argv[14]=\n",
      "argv[15]=\n",
      "argv[16]=\n",
      "argv[17]=\n",
      "argv[18]=\n",
      "argv[19]=\n",
      "argv[20]=\n",
      "argv[21]=--background_color_green=0.21176470588235294\n",
      "argv[22]=\n",
      "argv[23]=\n",
      "argv[24]=\n",
      "argv[25]=\n",
      "argv[26]=\n",
      "argv[27]=\n",
      "argv[28]=\n",
      "argv[29]=\n",
      "argv[30]=\n",
      "argv[31]=\n",
      "argv[32]=\n",
      "argv[33]=\n",
      "argv[34]=\n",
      "argv[35]=\n",
      "argv[36]=\n",
      "argv[37]=\n",
      "argv[38]=\n",
      "argv[39]=\n",
      "argv[40]=\n",
      "argv[41]=\n",
      "argv[42]=--background_color_blue=0.17647058823529413\n",
      "argv[0]=--background_color_red=0.8745098039215686\n",
      "argv[1]=\n",
      "argv[2]=\n",
      "argv[3]=\n",
      "argv[4]=\n",
      "argv[5]=\n",
      "argv[6]=\n",
      "argv[7]=\n",
      "argv[8]=\n",
      "argv[9]=\n",
      "argv[10]=\n",
      "argv[11]=\n",
      "argv[12]=\n",
      "argv[13]=\n",
      "argv[14]=\n",
      "argv[15]=\n",
      "argv[16]=\n",
      "argv[17]=\n",
      "argv[18]=\n",
      "argv[19]=\n",
      "argv[20]=\n",
      "argv[21]=--background_color_green=0.21176470588235294\n",
      "argv[22]=\n",
      "argv[23]=\n",
      "argv[24]=\n",
      "argv[25]=\n",
      "argv[26]=\n",
      "argv[27]=\n",
      "argv[28]=\n",
      "argv[29]=\n",
      "argv[30]=\n",
      "argv[31]=\n",
      "argv[32]=\n",
      "argv[33]=\n",
      "argv[34]=\n",
      "argv[35]=\n",
      "argv[36]=\n",
      "argv[37]=\n",
      "argv[38]=\n",
      "argv[39]=\n",
      "argv[40]=\n",
      "argv[41]=\n",
      "argv[42]=--background_color_blue=0.17647058823529413\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=45\n",
      "argv[0] = --unused\n",
      "argv[1] = --background_color_red=0.8745098039215686\n",
      "argv[2] = \n",
      "argv[3] = \n",
      "argv[4] = \n",
      "argv[5] = \n",
      "argv[6] = \n",
      "argv[7] = \n",
      "argv[8] = \n",
      "argv[9] = \n",
      "argv[10] = \n",
      "argv[11] = \n",
      "argv[12] = \n",
      "argv[13] = \n",
      "argv[14] = \n",
      "argv[15] = \n",
      "argv[16] = \n",
      "argv[17] = \n",
      "argv[18] = \n",
      "argv[19] = \n",
      "argv[20] = \n",
      "argv[21] = \n",
      "argv[22] = --background_color_green=0.21176470588235294\n",
      "argv[23] = \n",
      "argv[24] = \n",
      "argv[25] = \n",
      "argWrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"PandaPush-v2\", render=True) # creating the environnment with rendering\n",
    "model = DDPG.load(\"PandaPush-v2-model\", env=env) # load the best version of the model\n",
    "obs = env.reset()\n",
    "dones = False\n",
    "\n",
    "while not dones:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e1cb3",
   "metadata": {},
   "source": [
    "## 7. Testing community trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f921fe70",
   "metadata": {},
   "source": [
    "### 7.1 import sb3_contrib dependancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a761528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panda_gym\n",
    "from sb3_contrib import TQC\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from sb3_contrib.common.wrappers import TimeFeatureWrapper\n",
    "from stable_baselines3.common.logger import configure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82872c94",
   "metadata": {},
   "source": [
    "### 7.2 loading and running community trained model with [TQC](https://sb3-contrib.readthedocs.io/en/master/modules/tqc.html) model\n",
    "\n",
    "Since training a robotic model demands a lot of computing power we were not able to creat a satisfying model. Let's try one model given by the community throught sb3_contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "836fcd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david_ekchajzer/Workplace/MIAGE/ML/reinforcement_learning_use_cases/robotic/venv/lib/python3.9/site-packages/gym/spaces/box.py:78: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/home/david_ekchajzer/Workplace/MIAGE/ML/reinforcement_learning_use_cases/robotic/venv/lib/python3.9/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = make_vec_env(\"PandaPush-v2\", wrapper_class=TimeFeatureWrapper, env_kwargs={'render':True})\n",
    "model = TQC.load(\"logs/TQC/PandaPush-v1\", custom_objects={'learning_rate':0.001}, env=env)\n",
    "obs = env.reset()\n",
    "dones = False\n",
    "while not dones:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f163d540",
   "metadata": {},
   "source": [
    "## 8. Creating GIF\n",
    "\n",
    "Exporting a gif of the environnment with the model taken from community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab4ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v[26] = \n",
      "argv[27] = \n",
      "argv[28] = \n",
      "argv[29] = \n",
      "argv[30] = \n",
      "argv[31] = \n",
      "argv[32] = \n",
      "argv[33] = \n",
      "argv[34] = \n",
      "argv[35] = \n",
      "argv[36] = \n",
      "argv[37] = \n",
      "argv[38] = \n",
      "argv[39] = \n",
      "argv[40] = \n",
      "argv[41] = \n",
      "argv[42] = \n",
      "argv[43] = --background_color_blue=0.17647058823529413\n",
      "argv[44] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Intel\n",
      "GL_RENDERER=Mesa Intel(R) HD Graphics 620 (KBL GT2)\n",
      "GL_VERSION=4.6 (Core Profile) Mesa 21.2.6\n",
      "GL_SHADING_LANGUAGE_VERSION=4.60\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.6 (Core Profile) Mesa 21.2.6\n",
      "Vendor = Intel\n",
      "Renderer = Mesa Intel(R) HD Graphics 620 (KBL GT2)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "numActiveThreads = 0\n",
      "stopping threads\n",
      "Thread with taskId 0 exiting\n",
      "Thread TERMINATED\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n",
      "finished\n",
      "numActiveThreads = 0\n",
      "btShutDownExampleBrowser stopping threads\n",
      "Thread with taskId 0 exiting\n",
      "Thread TERMINATED\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n",
      "argv[0]=--background_color_red=0.8745098039215686\n",
      "argv[1]=\n",
      "argv[2]=\n",
      "argv[3]=\n",
      "argv[4]=\n",
      "argv[5]=\n",
      "argv[6]=\n",
      "argv[7]=\n",
      "argv[8]=\n",
      "argv[9]=\n",
      "argv[10]=\n",
      "argv[11]=\n",
      "argv[12]=\n",
      "argv[13]=\n",
      "argv[14]=\n",
      "argv[15]=\n",
      "argv[16]=\n",
      "argv[17]=\n",
      "argv[18]=\n",
      "argv[19]=\n",
      "argv[20]=\n",
      "argv[21]=--background_color_green=0.21176470588235294\n",
      "argv[22]=\n",
      "argv[23]=\n",
      "argv[24]=\n",
      "argv[25]=\n",
      "argv[26]=\n",
      "argv[27]=\n",
      "argv[28]=\n",
      "argv[29]=\n",
      "argv[30]=\n",
      "argv[31]=\n",
      "argv[32]=\n",
      "argv[33]=\n",
      "argv[34]=\n",
      "argv[35]=\n",
      "argv[36]=\n",
      "argv[37]=\n",
      "argv[38]=\n",
      "argv[39]=\n",
      "argv[40]=\n",
      "argv[41]=\n",
      "argv[42]=--background_color_blue=0.17647058823529413\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=45\n",
      "argv[0] = --unused\n",
      "argv[1] = --background_color_red=0.8745098039215686\n",
      "argv[2] = \n",
      "argv[3] = \n",
      "argv[4] = \n",
      "argv[5] = \n",
      "argv[6] = \n",
      "argv[7] = \n",
      "argv[8] = \n",
      "argv[9] = \n",
      "argv[10] = \n",
      "argv[11] = \n",
      "argv[12] = \n",
      "argv[13] = \n",
      "argv[14] = \n",
      "argv[15] = \n",
      "argv[16] = \n",
      "argv[17] = \n",
      "argv[18] = \n",
      "argv[19] = \n",
      "argv[20] = \n",
      "argv[21] = \n",
      "argv[22] = --background_color_green=0.21176470588235294\n",
      "argv[23] = \n",
      "argv[24] = \n",
      "argv[25] = \n",
      "argv[26] = \n",
      "argv[27] = \n",
      "argv[28] = \n",
      "argv[29] = \n",
      "argv[30] = \n",
      "argv[31] = \n",
      "argv[32] = \n",
      "argv[33] = \n",
      "argv[34] = \n",
      "argv[35] = \n",
      "argv[36] = \n",
      "argv[37] = \n",
      "argv[38] = \n",
      "argv[39] = \n",
      "argv[40] = \n",
      "argv[41] = \n",
      "argv[42] = \n",
      "argv[43] = --background_color_blue=0.17647058823529413\n",
      "argv[44] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Intel\n",
      "GL_RENDERER=Mesa Intel(R) HD Graphics 620 (KBL GT2)\n",
      "GL_VERSION=4.6 (Core Profile) Mesa 21.2.6\n",
      "GL_SHADING_LANGUAGE_VERSION=4.60\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.6 (Core Profile) Mesa 21.2.6\n",
      "Vendor = Intel\n",
      "Renderer = Mesa Intel(R) HD Graphics 620 (KBL GT2)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "numActiveThreads = 0\n",
      "stopping threads\n",
      "Thread with taskId 0 exiting\n",
      "Thread TERMINATED\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n",
      "finished\n",
      "numActiveThreads = 0\n",
      "btShutDownExampleBrowser stopping threads\n",
      "Thread with taskId 0 exiting\n",
      "Thread TERMINATED\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n",
      "argv[0]=--background_color_red=0.8745098039215686\n",
      "argv[1]=\n",
      "argv[2]=\n",
      "a"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import numpy\n",
    "\n",
    "gif_env = make_vec_env(\"PandaPush-v2\", wrapper_class=TimeFeatureWrapper, env_kwargs={'render':True})\n",
    "gif_model = TQC.load(\"logs/TQC/PandaPush-v1\", custom_objects={'learning_rate':0.001}, env=gif_env)\n",
    "images = []\n",
    "obs = gif_env.reset()\n",
    "img = gif_env.render(mode='rgb_array')\n",
    "\n",
    "for i in range(350):\n",
    "    images.append(img)\n",
    "    action, _ = gif_model.predict(obs)\n",
    "    obs, _, _, _ = gif_env.step(action)\n",
    "    img = gif_env.render(mode='rgb_array')\n",
    "\n",
    "imageio.mimsave('test_panda_push.gif',\n",
    "                [numpy.array(img) for i, img in enumerate(images) if i % 2 == 0],\n",
    "                fps=29)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2f1b65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
